{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0340b2b5-04a4-4a7f-b5ad-19ff4a30207f",
   "metadata": {},
   "source": [
    "# Model for audio data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1c58f-d275-4b39-82cb-9ec06349b322",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370eb3e4-97f2-401c-83ba-b849b83761c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 20:28:05.664587: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-07 20:28:05.664940: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-07 20:28:05.674522: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-07 20:28:05.749275: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-07 20:28:10.745191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.26.4\n",
      "CUDA version: 11.8 - Torch versteion: 2.0.0+cu118 - device count: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7b7f37fcb570>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../') \n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Subset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd \n",
    "# from MAE code\n",
    "from util.datasets import build_dataset\n",
    "import argparse\n",
    "import util.misc as misc\n",
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import timm\n",
    "\n",
    "assert timm.__version__ == \"0.3.2\" # version check\n",
    "from timm.models.layers import trunc_normal_\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "\n",
    "import util.lr_decay as lrd\n",
    "import util.misc as misc\n",
    "from util.datasets import build_dataset\n",
    "from util.pos_embed import interpolate_pos_embed\n",
    "from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "\n",
    "import models_vit\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import models_mae\n",
    "import torch; print(f'numpy version: {np.__version__}\\nCUDA version: {torch.version.cuda} - Torch versteion: {torch.__version__} - device count: {torch.cuda.device_count()}')\n",
    "\n",
    "from engine_finetune import train_one_epoch, evaluate\n",
    "from timm.data import Mixup\n",
    "from timm.utils import accuracy\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch.optim as optim\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def show_image(image, title=''):\n",
    "    # image is [H, W, 3]\n",
    "    assert image.shape[2] == 3\n",
    "    plt.imshow(torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int())\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.axis('off')\n",
    "    return\n",
    "\n",
    "def prepare_model(chkpt_dir, arch='mae_vit_large_patch16'):\n",
    "    # build model\n",
    "    model = getattr(models_mae, arch)()\n",
    "    # load model\n",
    "    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n",
    "    msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    print(msg)\n",
    "    return model\n",
    "\n",
    "def run_one_image(img, model):\n",
    "    x = torch.tensor(img)\n",
    "\n",
    "    # make it a batch-like\n",
    "    x = x.unsqueeze(dim=0)\n",
    "    x = torch.einsum('nhwc->nchw', x)\n",
    "\n",
    "    # run MAE\n",
    "    loss, y, mask = model(x.float(), mask_ratio=0.75)\n",
    "    y = model.unpatchify(y)\n",
    "    y = torch.einsum('nchw->nhwc', y).detach().cpu()\n",
    "\n",
    "    # visualize the mask\n",
    "    mask = mask.detach()\n",
    "    mask = mask.unsqueeze(-1).repeat(1, 1, model.patch_embed.patch_size[0]**2 *3)  # (N, H*W, p*p*3)\n",
    "    mask = model.unpatchify(mask)  # 1 is removing, 0 is keeping\n",
    "    mask = torch.einsum('nchw->nhwc', mask).detach().cpu()\n",
    "\n",
    "    x = torch.einsum('nchw->nhwc', x)\n",
    "\n",
    "    # masked image\n",
    "    im_masked = x * (1 - mask)\n",
    "\n",
    "    # MAE reconstruction pasted with visible patches\n",
    "    im_paste = x * (1 - mask) + y * mask\n",
    "\n",
    "    # make the plt figure larger\n",
    "    plt.rcParams['figure.figsize'] = [24, 24]\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    show_image(x[0], \"original\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    show_image(im_masked[0], \"masked\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    show_image(y[0], \"reconstruction\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    show_image(im_paste[0], \"reconstruction + visible\")\n",
    "\n",
    "    plt.show()\n",
    "# Set the seed for PyTorch\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503539d-e62d-446e-86a1-e5f43a7e84e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parametrize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac00b4c-52e2-4b86-a7d3-0a2734bc76c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:41.092408] [20:29:41.092206] [20:29:41.092850] Not using distributed mode\n",
      "[20:29:41.093353] [20:29:41.093347] [20:29:41.093377] [20:29:41.093334] [20:29:41.093391] [20:29:41.093388] [20:29:41.093399] Namespace(batch_size=256,\n",
      "epochs=50,\n",
      "accum_iter=4,\n",
      "model='mobilenet_v3',\n",
      "input_size=224,\n",
      "drop_path=0.1,\n",
      "clip_grad=None,\n",
      "weight_decay=0.05,\n",
      "lr=None,\n",
      "blr=0.0005,\n",
      "layer_decay=0.65,\n",
      "min_lr=1e-06,\n",
      "warmup_epochs=5,\n",
      "color_jitter=None,\n",
      "aa='rand-m9-mstd0.5-inc1',\n",
      "smoothing=0.1,\n",
      "reprob=0.25,\n",
      "remode='pixel',\n",
      "recount=1,\n",
      "resplit=False,\n",
      "mixup=0.8,\n",
      "cutmix=1.0,\n",
      "cutmix_minmax=None,\n",
      "mixup_prob=1.0,\n",
      "mixup_switch_prob=0.5,\n",
      "mixup_mode='batch',\n",
      "finetune='mae_pretrain_vit_base.pth',\n",
      "global_pool=True,\n",
      "data_path='/media/enc/vera1/sebastian/data/ABGQI_mel_spectrograms',\n",
      "nb_classes=5,\n",
      "output_dir='quinn_5_classes',\n",
      "log_dir='/media/enc/vera1/sebastian/codes/classifiers/mae/MobileNet/output_dir',\n",
      "device='cuda',\n",
      "seed=0,\n",
      "resume='/media/enc/vera1/sebastian/codes/classifiers/mae/MobileNet/quinn_5_classes/checkpoint-49.pth',\n",
      "start_epoch=0,\n",
      "eval=True,\n",
      "dist_eval=False,\n",
      "num_workers=10,\n",
      "pin_mem=True,\n",
      "world_size=1,\n",
      "local_rank=-1,\n",
      "dist_on_itp=False,\n",
      "dist_url='env://',\n",
      "distributed=False)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser('MAE fine-tuning for image classification', add_help=False)\n",
    "parser.add_argument('--batch_size', default=256, type=int,\n",
    "                        help='Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus')\n",
    "parser.add_argument('--epochs', default=50, type=int)\n",
    "parser.add_argument('--accum_iter', default=4, type=int,\n",
    "                        help='Accumulate gradient iterations (for increasing the effective batch size under memory constraints)')\n",
    "\n",
    "    # Model parameters\n",
    "parser.add_argument('--model', default='mobilenet_v3', type=str, metavar='MODEL',\n",
    "                        help='Name of model to train')\n",
    "\n",
    "parser.add_argument('--input_size', default=224, type=int,\n",
    "                        help='images input size')\n",
    "\n",
    "parser.add_argument('--drop_path', type=float, default=0.1, metavar='PCT',\n",
    "                        help='Drop path rate (default: 0.1)')\n",
    "\n",
    "    # Optimizer parameters\n",
    "parser.add_argument('--clip_grad', type=float, default=None, metavar='NORM',\n",
    "                        help='Clip gradient norm (default: None, no clipping)')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.05,\n",
    "                        help='weight decay (default: 0.05)')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=None, metavar='LR',\n",
    "                        help='learning rate (absolute lr)')\n",
    "parser.add_argument('--blr', type=float, default=5e-4, metavar='LR',\n",
    "                        help='base learning rate: absolute_lr = base_lr * total_batch_size / 256')\n",
    "parser.add_argument('--layer_decay', type=float, default=0.65,\n",
    "                        help='layer-wise lr decay from ELECTRA/BEiT')\n",
    "\n",
    "parser.add_argument('--min_lr', type=float, default=1e-6, metavar='LR',\n",
    "                        help='lower lr bound for cyclic schedulers that hit 0')\n",
    "\n",
    "parser.add_argument('--warmup_epochs', type=int, default=5, metavar='N',\n",
    "                        help='epochs to warmup LR')\n",
    "\n",
    "    # Augmentation parameters\n",
    "parser.add_argument('--color_jitter', type=float, default=None, metavar='PCT',\n",
    "                        help='Color jitter factor (enabled only when not using Auto/RandAug)')\n",
    "parser.add_argument('--aa', type=str, default='rand-m9-mstd0.5-inc1', metavar='NAME',\n",
    "                        help='Use AutoAugment policy. \"v0\" or \"original\". \" + \"(default: rand-m9-mstd0.5-inc1)'),\n",
    "parser.add_argument('--smoothing', type=float, default=0.1,\n",
    "                        help='Label smoothing (default: 0.1)')\n",
    "\n",
    "    # * Random Erase params\n",
    "parser.add_argument('--reprob', type=float, default=0.25, metavar='PCT',\n",
    "                        help='Random erase prob (default: 0.25)')\n",
    "parser.add_argument('--remode', type=str, default='pixel',\n",
    "                        help='Random erase mode (default: \"pixel\")')\n",
    "parser.add_argument('--recount', type=int, default=1,\n",
    "                        help='Random erase count (default: 1)')\n",
    "parser.add_argument('--resplit', action='store_true', default=False,\n",
    "                        help='Do not random erase first (clean) augmentation split')\n",
    "    # * Mixup params\n",
    "parser.add_argument('--mixup', type=float, default=0.8,\n",
    "                        help='mixup alpha, mixup enabled if > 0.')\n",
    "parser.add_argument('--cutmix', type=float, default=1.0,\n",
    "                        help='cutmix alpha, cutmix enabled if > 0.')\n",
    "parser.add_argument('--cutmix_minmax', type=float, nargs='+', default=None,\n",
    "                        help='cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)')\n",
    "parser.add_argument('--mixup_prob', type=float, default=1.0,\n",
    "                        help='Probability of performing mixup or cutmix when either/both is enabled')\n",
    "parser.add_argument('--mixup_switch_prob', type=float, default=0.5,\n",
    "                        help='Probability of switching to cutmix when both mixup and cutmix enabled')\n",
    "\n",
    "parser.add_argument('--mixup_mode', type=str, default='batch',\n",
    "                        help='How to apply mixup/cutmix params. Per \"batch\", \"pair\", or \"elem\"')\n",
    "\n",
    "    # * Finetuning params\n",
    "parser.add_argument('--finetune', default='mae_pretrain_vit_base.pth',\n",
    "                        help='finetune from checkpoint')\n",
    "parser.add_argument('--global_pool', action='store_true')\n",
    "parser.set_defaults(global_pool=True)\n",
    "parser.add_argument('--cls_token', action='store_false', dest='global_pool',\n",
    "                        help='Use class token instead of global pool for classification')\n",
    "\n",
    "    # Dataset parameters\n",
    "parser.add_argument('--data_path', default='/media/enc/vera1/sebastian/data/ABGQI_mel_spectrograms', type=str,\n",
    "                        help='dataset path')\n",
    "parser.add_argument('--nb_classes', default=5, type=int,\n",
    "                        help='number of the classification types')\n",
    "\n",
    "parser.add_argument('--output_dir', default='quinn_5_classes',\n",
    "                        help='path where to save, empty for no saving')\n",
    "parser.add_argument('--log_dir', default='/media/enc/vera1/sebastian/codes/classifiers/mae/MobileNet/output_dir',\n",
    "                        help='path where to tensorboard log')\n",
    "parser.add_argument('--device', default='cuda',\n",
    "                        help='device to use for training / testing')\n",
    "parser.add_argument('--seed', default=0, type=int)\n",
    "parser.add_argument('--resume', default=\"/media/enc/vera1/sebastian/codes/classifiers/mae/MobileNet/quinn_5_classes/checkpoint-49.pth\",\n",
    "                        help='resume from checkpoint')\n",
    "\n",
    "parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "parser.add_argument('--eval',default=True, action='store_true',\n",
    "                        help='Perform evaluation only')\n",
    "parser.add_argument('--dist_eval', action='store_true', default=False,\n",
    "                        help='Enabling distributed evaluation (recommended during training for faster monitor')\n",
    "parser.add_argument('--num_workers', default=10, type=int)\n",
    "parser.add_argument('--pin_mem', action='store_true',\n",
    "                        help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "parser.add_argument('--no_pin_mem', action='store_false', dest='pin_mem')\n",
    "parser.set_defaults(pin_mem=True)\n",
    "\n",
    "    # distributed training parameters\n",
    "parser.add_argument('--world_size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "parser.add_argument('--local_rank', default=-1, type=int)\n",
    "parser.add_argument('--dist_on_itp', action='store_true')\n",
    "parser.add_argument('--dist_url', default='env://',\n",
    "                        help='url used to set up distributed training')\n",
    "args, unknown = parser.parse_known_args()\n",
    "misc.init_distributed_mode(args)\n",
    "print(\"{}\".format(args).replace(', ', ',\\n'))\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "device = torch.device(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e73e12-e66b-40eb-b5a2-88a23ef3ba96",
   "metadata": {},
   "source": [
    "## Designing a frozen mobileNetv2 \n",
    "Deleting only the classifier layer, then replacing it with a linearizer. https://stackoverflow.com/questions/69321848/fine-tuning-pretrained-model-mobilenet-v3-large-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75499fb9-7835-4c7b-b83b-96048004eada",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:46.002116] [20:29:46.002097] [20:29:46.002704] [20:29:46.001881] [20:29:46.002725] [20:29:46.002722] [20:29:46.002734] BEFORE Trainable params: 0 of 5483032\n",
      "[20:29:46.358745] [20:29:46.358730] [20:29:46.359194] [20:29:46.358567] [20:29:46.359212] [20:29:46.359211] [20:29:46.359218] AFTER Trainable params: 1236485 of 4208437\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "def count_parameters(model, message=\"\"):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"{message} Trainable params: {trainable_params} of {total_params}\")\n",
    "\n",
    "# Load pre-trained MobileNetV3 model\n",
    "frozen_model = models.mobilenet_v3_large(pretrained=True, progress=True)\n",
    "\n",
    "# Freeze all layers except the classifier\n",
    "for param in frozen_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "count_parameters(frozen_model, \"BEFORE\")\n",
    "\n",
    "# Modify the classifier to fit the new number of classes\n",
    "num_classes = args.nb_classes\n",
    "in_features = frozen_model.classifier[-1].in_features\n",
    "frozen_model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "num_layers_unfreeze = 50\n",
    "# Unfreeze the last layer for fine-tuning\n",
    "for param in frozen_model.classifier[-num_layers_unfreeze:].parameters():\n",
    "    # if not isinstance(param, nn.BatchNorm2d):# not working anyway.. \n",
    "        param.requires_grad = True\n",
    "\n",
    "import copy\n",
    "stage_1_model = copy.deepcopy(frozen_model)\n",
    "\n",
    "count_parameters(stage_1_model, \"AFTER\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bee8a635-666d-4023-bb34-c0f75f7dd136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create random input data\n",
    "# batch_size = 1\n",
    "# channels = 3\n",
    "# height = 224\n",
    "# width = 224\n",
    "# random_input = torch.randn(batch_size, channels, height, width)\n",
    "\n",
    "# # Forward pass through the model\n",
    "# output = stage_1_model(random_input)\n",
    "# print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e52885-7e00-4ebd-8f8e-a21c2afb0011",
   "metadata": {},
   "source": [
    "since pytorch > 1.8, then have to update this i ~/anaconda3/lib/python3.11/site-packages/timm/models/layers/helpers.py with https://github.com/huggingface/pytorch-image-models/issues/420 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efcb2899-533c-4472-b263-b94f4d90f256",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:46.430290] [20:29:46.430287] [20:29:46.433929] [20:29:46.430264] [20:29:46.433970] [20:29:46.433961] [20:29:46.433982] Not using distributed mode\n",
      "[20:29:46.434440] [20:29:46.434437] [20:29:46.434455] [20:29:46.434435] [20:29:46.434468] [20:29:46.434466] [20:29:46.434475] [20:29:46.434431] [20:29:46.434488] [20:29:46.434486] [20:29:46.434494] [20:29:46.434484] [20:29:46.434502] [20:29:46.434500] [20:29:46.434513] Namespace(batch_size=256,\n",
      "epochs=50,\n",
      "accum_iter=4,\n",
      "model='mobilenet_v3',\n",
      "input_size=224,\n",
      "drop_path=0.1,\n",
      "clip_grad=None,\n",
      "weight_decay=0.05,\n",
      "lr=None,\n",
      "blr=0.0005,\n",
      "layer_decay=0.65,\n",
      "min_lr=1e-06,\n",
      "warmup_epochs=5,\n",
      "color_jitter=None,\n",
      "aa='rand-m9-mstd0.5-inc1',\n",
      "smoothing=0.1,\n",
      "reprob=0.25,\n",
      "remode='pixel',\n",
      "recount=1,\n",
      "resplit=False,\n",
      "mixup=0.8,\n",
      "cutmix=1.0,\n",
      "cutmix_minmax=None,\n",
      "mixup_prob=1.0,\n",
      "mixup_switch_prob=0.5,\n",
      "mixup_mode='batch',\n",
      "finetune='mae_pretrain_vit_base.pth',\n",
      "global_pool=True,\n",
      "data_path='/media/enc/vera1/sebastian/data/ABGQI_mel_spectrograms',\n",
      "nb_classes=5,\n",
      "output_dir='quinn_5_classes',\n",
      "log_dir='/media/enc/vera1/sebastian/codes/classifiers/mae/MobileNet/output_dir',\n",
      "device='cuda',\n",
      "seed=0,\n",
      "resume='/media/enc/vera1/sebastian/codes/classifiers/mae/MobileNet/quinn_5_classes/checkpoint-49.pth',\n",
      "start_epoch=0,\n",
      "eval=True,\n",
      "dist_eval=False,\n",
      "num_workers=10,\n",
      "pin_mem=True,\n",
      "world_size=1,\n",
      "local_rank=-1,\n",
      "dist_on_itp=False,\n",
      "dist_url='env://',\n",
      "distributed=False)\n",
      "[20:29:46.495343] [20:29:46.495336] [20:29:46.495420] [20:29:46.495331] [20:29:46.495442] [20:29:46.495439] [20:29:46.495458] [20:29:46.495242] [20:29:46.495472] [20:29:46.495470] [20:29:46.495480] [20:29:46.495467] [20:29:46.495493] [20:29:46.495490] [20:29:46.495506] Dataset ImageFolder\n",
      "    Number of datapoints: 7814\n",
      "    Root location: /media/enc/vera1/sebastian/data/ABGQI_mel_spectrograms/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               <timm.data.auto_augment.RandAugment object at 0x7b7d09ab80d0>\n",
      "               ToTensor()\n",
      "               Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      "               <timm.data.random_erasing.RandomErasing object at 0x7b7cc9424b10>\n",
      "           )\n",
      "[20:29:46.513899] [20:29:46.513896] [20:29:46.513931] [20:29:46.513889] [20:29:46.513946] [20:29:46.513945] [20:29:46.513956] [20:29:46.513857] [20:29:46.513966] [20:29:46.513963] [20:29:46.513972] [20:29:46.513962] [20:29:46.513978] [20:29:46.513977] [20:29:46.513987] Dataset ImageFolder\n",
      "    Number of datapoints: 850\n",
      "    Root location: /media/enc/vera1/sebastian/data/ABGQI_mel_spectrograms/val\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=256, interpolation=bicubic, max_size=None, antialias=warn)\n",
      "               CenterCrop(size=(224, 224))\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      "           )\n",
      "[20:29:46.514637] [20:29:46.514635] [20:29:46.514649] [20:29:46.514632] [20:29:46.514656] [20:29:46.514655] [20:29:46.514664] [20:29:46.514623] [20:29:46.514676] [20:29:46.514674] [20:29:46.514681] [20:29:46.514673] [20:29:46.514688] [20:29:46.514686] [20:29:46.514693] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7b7d09aa9690>\n"
     ]
    }
   ],
   "source": [
    "misc.init_distributed_mode(args)\n",
    "\n",
    "    # print('job dir: {}'.format(os.path.dirname(os.path.realpath(__file__))))\n",
    "print(\"{}\".format(args).replace(', ', ',\\n'))\n",
    "\n",
    "device = torch.device(args.device)\n",
    "\n",
    "seed = args.seed + misc.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "dataset_train = build_dataset(is_train=True, args=args)\n",
    "dataset_val = build_dataset(is_train=False, args=args)\n",
    "\n",
    "if True:  # args.distributed:\n",
    "        num_tasks = misc.get_world_size()\n",
    "        global_rank = misc.get_rank()\n",
    "        sampler_train = torch.utils.data.DistributedSampler(\n",
    "            dataset_train, num_replicas=num_tasks, rank=global_rank, shuffle=True\n",
    "        )\n",
    "        print(\"Sampler_train = %s\" % str(sampler_train))\n",
    "        if args.dist_eval:\n",
    "            if len(dataset_val) % num_tasks != 0:\n",
    "                print('Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. '\n",
    "                      'This will slightly alter validation results as extra duplicate entries are added to achieve '\n",
    "                      'equal num of samples per-process.')\n",
    "            sampler_val = torch.utils.data.DistributedSampler(\n",
    "                dataset_val, num_replicas=num_tasks, rank=global_rank, shuffle=True)  # shuffle=True to reduce monitor bias\n",
    "        else:\n",
    "            sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "else:\n",
    "        sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "        sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "\n",
    "if global_rank == 0 and args.log_dir is not None and not args.eval:\n",
    "        os.makedirs(args.log_dir, exist_ok=True)\n",
    "        log_writer = SummaryWriter(log_dir=args.log_dir)\n",
    "else:\n",
    "        log_writer = None\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train, sampler=sampler_train,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=True,\n",
    ")\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val, sampler=sampler_val,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cd05d05-9434-4c06-a03a-801f4f2a59ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:46.637042] [20:29:46.637040] [20:29:46.637424] [20:29:46.636956] [20:29:46.637445] [20:29:46.637440] [20:29:46.637457] [20:29:46.636095] [20:29:46.637491] [20:29:46.637488] [20:29:46.637508] [20:29:46.637475] [20:29:46.637549] [20:29:46.637538] [20:29:46.637557] Mixup is activated!\n",
      "[20:29:48.508286] [20:29:48.508267] [20:29:48.508728] [20:29:48.508238] [20:29:48.508754] [20:29:48.508750] [20:29:48.508763] [20:29:48.508038] [20:29:48.508787] [20:29:48.508784] [20:29:48.508795] [20:29:48.508780] [20:29:48.508809] [20:29:48.508807] [20:29:48.508818] Model = MobileNetV3(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Conv2dNormActivation(\n",
      "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
      "    (1): Hardswish()\n",
      "    (2): Dropout(p=0.2, inplace=True)\n",
      "    (3): Linear(in_features=1280, out_features=5, bias=True)\n",
      "  )\n",
      ")\n",
      "[20:29:48.509180] [20:29:48.509178] [20:29:48.509198] [20:29:48.509176] [20:29:48.509211] [20:29:48.509206] [20:29:48.509221] [20:29:48.509169] [20:29:48.509242] [20:29:48.509240] [20:29:48.509250] [20:29:48.509237] [20:29:48.509262] [20:29:48.509260] [20:29:48.509276] number of params (M): 1.24\n",
      "[20:29:48.509729] [20:29:48.509726] [20:29:48.509745] [20:29:48.509721] [20:29:48.509756] [20:29:48.509754] [20:29:48.509767] [20:29:48.509713] [20:29:48.509782] [20:29:48.509780] [20:29:48.509790] [20:29:48.509778] [20:29:48.509799] [20:29:48.509797] [20:29:48.509806] base lr: 5.00e-04\n",
      "[20:29:48.509874] [20:29:48.509872] [20:29:48.509886] [20:29:48.509870] [20:29:48.509895] [20:29:48.509893] [20:29:48.509902] [20:29:48.509866] [20:29:48.509915] [20:29:48.509912] [20:29:48.509922] [20:29:48.509910] [20:29:48.509932] [20:29:48.509929] [20:29:48.509944] actual lr: 2.00e-03\n",
      "[20:29:48.510013] [20:29:48.510011] [20:29:48.510022] [20:29:48.510009] [20:29:48.510031] [20:29:48.510029] [20:29:48.510038] [20:29:48.510005] [20:29:48.510051] [20:29:48.510048] [20:29:48.510060] [20:29:48.510046] [20:29:48.510069] [20:29:48.510067] [20:29:48.510081] accumulate grad iterations: 4\n",
      "[20:29:48.510138] [20:29:48.510136] [20:29:48.510147] [20:29:48.510134] [20:29:48.510156] [20:29:48.510154] [20:29:48.510163] [20:29:48.510131] [20:29:48.510201] [20:29:48.510199] [20:29:48.510208] [20:29:48.510196] [20:29:48.510219] [20:29:48.510216] [20:29:48.510225] effective batch size: 1024\n",
      "[20:29:48.518411] [20:29:48.518408] [20:29:48.518432] [20:29:48.518405] [20:29:48.518444] [20:29:48.518441] [20:29:48.518451] [20:29:48.518388] [20:29:48.518470] [20:29:48.518468] [20:29:48.518478] [20:29:48.518465] [20:29:48.518487] [20:29:48.518485] [20:29:48.518494] criterion = SoftTargetCrossEntropy()\n",
      "[20:29:50.647424] [20:29:50.647396] [20:29:50.648854] [20:29:50.647381] [20:29:50.648887] [20:29:50.648883] [20:29:50.648900] [20:29:50.647004] [20:29:50.648927] [20:29:50.648925] [20:29:50.648944] [20:29:50.648923] [20:29:50.648959] [20:29:50.648956] [20:29:50.648969] Resume checkpoint /media/enc/vera1/sebastian/codes/classifiers/mae/MobileNet/quinn_5_classes/checkpoint-49.pth\n",
      "[20:30:28.997424] [20:30:28.997324] [20:30:29.006132] [20:30:28.997289] [20:30:29.006242] [20:30:29.006235] [20:30:29.006263] [20:30:28.996896] [20:30:29.006418] [20:30:29.006415] [20:30:29.006431] [20:30:29.006412] [20:30:29.006442] [20:30:29.006440] [20:30:29.006448] Test:  [0/4]  eta: 0:02:33  loss: 0.8027 (0.8027)  acc1: 72.2656 (72.2656)  acc5: 100.0000 (100.0000)  time: 38.3220  data: 20.7323  max mem: 1320\n",
      "[20:30:38.975157] [20:30:38.975153] [20:30:38.975795] [20:30:38.975147] [20:30:38.975817] [20:30:38.975814] [20:30:38.975831] [20:30:38.975027] [20:30:38.975854] [20:30:38.975847] [20:30:38.975860] [20:30:38.975845] [20:30:38.975872] [20:30:38.975870] [20:30:38.975879] Test:  [3/4]  eta: 0:00:12  loss: 0.8609 (0.8582)  acc1: 68.7500 (69.2941)  acc5: 100.0000 (100.0000)  time: 12.0713  data: 5.1842  max mem: 1320\n",
      "[20:30:39.509343] [20:30:39.509329] [20:30:39.510596] [20:30:39.509312] [20:30:39.510645] [20:30:39.510637] [20:30:39.510658] [20:30:39.509060] [20:30:39.510684] [20:30:39.510679] [20:30:39.510690] [20:30:39.510676] [20:30:39.510698] [20:30:39.510697] [20:30:39.510706] Test: Total time: 0:00:48 (12.2098 s / it)\n",
      "[20:30:39.511071] [20:30:39.511069] [20:30:39.511086] [20:30:39.511057] [20:30:39.511095] [20:30:39.511092] [20:30:39.511103] [20:30:39.511041] [20:30:39.511111] [20:30:39.511110] [20:30:39.511118] [20:30:39.511108] [20:30:39.511140] [20:30:39.511139] [20:30:39.511145] * Acc@1 69.294 Acc@5 100.000 loss 0.858\n",
      "[20:30:39.512851] [20:30:39.512847] [20:30:39.512869] [20:30:39.512845] [20:30:39.512877] [20:30:39.512875] [20:30:39.512882] [20:30:39.512824] [20:30:39.512896] [20:30:39.512895] [20:30:39.512901] [20:30:39.512893] [20:30:39.512908] [20:30:39.512906] [20:30:39.512914] Accuracy of the network on the 850 test images: 69.3%\n"
     ]
    }
   ],
   "source": [
    "mixup_fn = None\n",
    "mixup_active = args.mixup > 0 or args.cutmix > 0. or args.cutmix_minmax is not None\n",
    "if mixup_active:\n",
    "        print(\"Mixup is activated!\")\n",
    "        mixup_fn = Mixup(\n",
    "            mixup_alpha=args.mixup, cutmix_alpha=args.cutmix, cutmix_minmax=args.cutmix_minmax,\n",
    "            prob=args.mixup_prob, switch_prob=args.mixup_switch_prob, mode=args.mixup_mode,\n",
    "            label_smoothing=args.smoothing, num_classes=args.nb_classes)\n",
    "    \n",
    "# model = models_vit.__dict__[args.model](\n",
    "#         num_classes=args.nb_classes,\n",
    "#         drop_path_rate=args.drop_path,\n",
    "#         global_pool=args.global_pool,\n",
    "# )\n",
    "model = stage_1_model\n",
    "\n",
    "if args.finetune and not args.eval:\n",
    "        print(\"args.finetune and not args.eval\")\n",
    "        checkpoint = torch.load(args.finetune, map_location='cpu')\n",
    "\n",
    "        print(\"Load pre-trained checkpoint from: %s\" % args.finetune)\n",
    "        checkpoint_model = checkpoint['model']\n",
    "        state_dict = model.state_dict()\n",
    "        for k in ['head.weight', 'head.bias']:\n",
    "            if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "                print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "                del checkpoint_model[k]\n",
    "\n",
    "        # interpolate position embedding\n",
    "        interpolate_pos_embed(model, checkpoint_model)\n",
    "\n",
    "        # load pre-trained model\n",
    "        msg = model.load_state_dict(checkpoint_model, strict=False)\n",
    "        print(msg)\n",
    "\n",
    "        if args.global_pool:\n",
    "            assert set(msg.missing_keys) == {'head.weight', 'head.bias', 'fc_norm.weight', 'fc_norm.bias'}\n",
    "        else:\n",
    "            assert set(msg.missing_keys) == {'head.weight', 'head.bias'}\n",
    "\n",
    "        # manually initialize fc layer\n",
    "        trunc_normal_(model.head.weight, std=2e-5)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model_without_ddp = model\n",
    "\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Model = %s\" % str(model_without_ddp))\n",
    "print('number of params (M): %.2f' % (n_parameters / 1.e6))\n",
    "\n",
    "eff_batch_size = args.batch_size * args.accum_iter * misc.get_world_size()\n",
    "    \n",
    "if args.lr is None:  # only base_lr is specified\n",
    "        args.lr = args.blr * eff_batch_size / 256\n",
    "\n",
    "print(\"base lr: %.2e\" % (args.lr * 256 / eff_batch_size))\n",
    "print(\"actual lr: %.2e\" % args.lr)\n",
    "\n",
    "print(\"accumulate grad iterations: %d\" % args.accum_iter)\n",
    "print(\"effective batch size: %d\" % eff_batch_size)\n",
    "\n",
    "if args.distributed:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "        model_without_ddp = model.module\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)#SEB\n",
    "# optimizer = torch.optim.AdamW(param_groups, lr=args.lr)\n",
    "loss_scaler = NativeScaler()\n",
    "\n",
    "if mixup_fn is not None:\n",
    "        # smoothing is handled with mixup label transform\n",
    "        criterion = SoftTargetCrossEntropy()\n",
    "elif args.smoothing > 0.:\n",
    "        criterion = LabelSmoothingCrossEntropy(smoothing=args.smoothing)\n",
    "else:\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"criterion = %s\" % str(criterion))\n",
    "\n",
    "misc.load_model(args=args, model_without_ddp=model_without_ddp, optimizer=optimizer, loss_scaler=loss_scaler)\n",
    "\n",
    "if args.eval:\n",
    "        test_stats = evaluate(data_loader_val, model, device)\n",
    "        print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")\n",
    "        # exit(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee713c-2882-48de-945a-c11123262717",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train model\n",
    "Run a conda environment or alternatively just run the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c8d1d-2082-4ef6-b434-4a971277ec72",
   "metadata": {},
   "source": [
    "### Base model\n",
    "Finetuning using the base vit pretrained model  which is downloaded from here (https://github.com/facebookresearch/mae?tab=readme-ov-file#fine-tuning-with-pre-trained-checkpoints). The way to find the correct finetunng is explaned here (https://github.com/facebookresearch/mae/issues?q=is%3Aissue+is%3Aopen+classes )\n",
    "\n",
    "`python main_finetune.py --accum_iter 4 --batch_size 32 --model vit_base_patch16 --finetune mae_pretrain_vit_base.pth --epochs 100 --blr 5e-4 --layer_decay 0.65 --weight_decay 0.05 --drop_path 0.1 --mixup 0.8 --cutmix 1.0 --reprob 0.25 --dist_eval --data_path /media/enc/vera1/sebastian/data/Data-set-Urban_Esc/ --nb_classes 7`\n",
    "\n",
    "Expected results: \n",
    "\n",
    "```\n",
    "[04:05:12.377034] * Acc@1 83.388 Acc@5 99.836 loss 0.572\n",
    "[04:05:12.377152] Accuracy of the network on the 608 test images: 83.4%\n",
    "[04:05:12.377165] Max accuracy: 83.55%\n",
    "[04:05:12.378265] Training time 0:46:57\n",
    "```\n",
    "\n",
    "### Large model\n",
    "\n",
    "\n",
    "`python main_finetune.py --accum_iter 4 --batch_size 16 --model vit_large_patch16 --finetune mae_pretrain_vit_large.pth --epochs 100 --blr 5e-4 --layer_decay 0.65 --weight_decay 0.05 --drop_path 0.1 --mixup 0.8 --cutmix 1.0 --reprob 0.25 --dist_eval --data_path /media/enc/vera1/sebastian/data/Data-set-Urban_Esc/ --nb_classes 7 --output_dir EXP_large_vit`\n",
    "\n",
    "Expected results: \n",
    "\n",
    "```\n",
    "[06:10:18.181183] Test: Total time: 0:00:04 (0.1237 s / it)\n",
    "[06:10:18.181592] * Acc@1 83.059 Acc@5 99.671 loss 0.586\n",
    "[06:10:18.181741] Accuracy of the network on the 608 test images: 83.1%\n",
    "[06:10:18.181759] Max accuracy: 83.06%\n",
    "[06:10:18.182753] Training time 1:18:19\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cfd5d05-fb33-4759-aa29-37debddc0e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = False\n",
    "\n",
    "if train:\n",
    "    print(f\"Start training for {args.epochs} epochs with batch size of {args.batch_size}\")\n",
    "    start_time = time.time()\n",
    "    max_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.distributed:\n",
    "            data_loader_train.sampler.set_epoch(epoch)\n",
    "        train_stats = train_one_epoch(\n",
    "            model, criterion, data_loader_train,\n",
    "            optimizer, device, epoch, loss_scaler,\n",
    "            args.clip_grad, mixup_fn,\n",
    "            log_writer=log_writer,\n",
    "            args=args\n",
    "        )\n",
    "        if args.output_dir:\n",
    "            misc.save_model(\n",
    "                args=args, model=model, model_without_ddp=model_without_ddp, optimizer=optimizer,\n",
    "                loss_scaler=loss_scaler, epoch=epoch)\n",
    "\n",
    "        test_stats = evaluate(data_loader_val, model, device)\n",
    "        print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")\n",
    "        max_accuracy = max(max_accuracy, test_stats[\"acc1\"])\n",
    "        print(f'Max accuracy: {max_accuracy:.2f}%')\n",
    "\n",
    "        if log_writer is not None:\n",
    "            log_writer.add_scalar('perf/test_acc1', test_stats['acc1'], epoch)\n",
    "            log_writer.add_scalar('perf/test_acc5', test_stats['acc5'], epoch)\n",
    "            log_writer.add_scalar('perf/test_loss', test_stats['loss'], epoch)\n",
    "\n",
    "        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
    "                        **{f'test_{k}': v for k, v in test_stats.items()},\n",
    "                        'epoch': epoch,\n",
    "                        'n_parameters': n_parameters}\n",
    "\n",
    "        if args.output_dir and misc.is_main_process():\n",
    "            if log_writer is not None:\n",
    "                log_writer.flush()\n",
    "            with open(os.path.join(args.output_dir, \"log.txt\"), mode=\"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(json.dumps(log_stats) + \"\\n\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Training time {}'.format(total_time_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f19af4-f98c-4cac-893b-45a39ee17caa",
   "metadata": {},
   "source": [
    "# Evaluate loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f3c948e-620d-448f-a08e-dd3f3a8e58e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"mobileNet\"\n",
    "\n",
    "saving_model = f\"{EXPERIMENT_NAME}/models\"\n",
    "os.makedirs(saving_model, exist_ok = True)\n",
    "os.makedirs(EXPERIMENT_NAME, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ebc1e78-3a15-40df-ad5f-6c0c756b6d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:54.207101] [20:30:54.206906] [20:30:54.210451] [20:30:54.206836] [20:30:54.210500] [20:30:54.210494] [20:30:54.210519] [20:30:54.206343] [20:30:54.210549] [20:30:54.210538] [20:30:54.210556] [20:30:54.210534] [20:30:54.210574] [20:30:54.210573] [20:30:54.210599] Test:  [0/4]  eta: 0:00:58  loss: 0.8027 (0.8027)  acc1: 72.2656 (72.2656)  acc5: 100.0000 (100.0000)  time: 14.6089  data: 14.3969  max mem: 1320\n",
      "[20:30:54.691545] [20:30:54.691540] [20:30:54.692201] [20:30:54.691525] [20:30:54.692289] [20:30:54.692280] [20:30:54.692313] [20:30:54.691400] [20:30:54.692383] [20:30:54.692378] [20:30:54.692394] [20:30:54.692376] [20:30:54.692408] [20:30:54.692405] [20:30:54.692414] Test:  [3/4]  eta: 0:00:03  loss: 0.8609 (0.8582)  acc1: 68.7500 (69.2941)  acc5: 100.0000 (100.0000)  time: 3.7716  data: 3.6037  max mem: 1320\n",
      "[20:30:55.157180] [20:30:55.157177] [20:30:55.157396] [20:30:55.157172] [20:30:55.157415] [20:30:55.157412] [20:30:55.157423] [20:30:55.157113] [20:30:55.157437] [20:30:55.157435] [20:30:55.157445] [20:30:55.157432] [20:30:55.157456] [20:30:55.157454] [20:30:55.157463] Test: Total time: 0:00:15 (3.8928 s / it)\n",
      "[20:30:55.157650] [20:30:55.157648] [20:30:55.157660] [20:30:55.157644] [20:30:55.157670] [20:30:55.157668] [20:30:55.157677] [20:30:55.157641] [20:30:55.157692] [20:30:55.157688] [20:30:55.157700] [20:30:55.157686] [20:30:55.157709] [20:30:55.157707] [20:30:55.157716] * Acc@1 69.294 Acc@5 100.000 loss 0.858\n",
      "[20:30:55.159285] [20:30:55.159281] [20:30:55.159303] [20:30:55.159276] [20:30:55.159316] [20:30:55.159313] [20:30:55.159323] [20:30:55.159250] [20:30:55.159338] [20:30:55.159335] [20:30:55.159345] [20:30:55.159333] [20:30:55.159354] [20:30:55.159352] [20:30:55.159364] Accuracy of the network on the 850 test images: 69.3%\n"
     ]
    }
   ],
   "source": [
    "if args.eval:\n",
    "        test_stats = evaluate(data_loader_val, model, device)\n",
    "        print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "285c69a2-6d2d-4368-9c9d-01bdf74613c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:40:42.848103] [20:40:42.848034] [20:40:42.850707] [20:40:42.847764] [20:40:42.850824] [20:40:42.850807] [20:40:42.850843] [20:40:42.847549] [20:40:42.850887] [20:40:42.850885] [20:40:42.850901] [20:40:42.850882] [20:40:42.850921] [20:40:42.850916] [20:40:42.850943] Test:  [0/4]  eta: 0:01:00  loss: 0.8027 (0.8027)  acc1: 72.2656 (72.2656)  acc5: 100.0000 (100.0000)  time: 15.1052  data: 14.9145  max mem: 1320\n",
      "[20:40:43.350701] [20:40:43.350690] [20:40:43.351930] [20:40:43.350676] [20:40:43.351976] [20:40:43.351973] [20:40:43.351988] [20:40:43.350480] [20:40:43.352005] [20:40:43.352003] [20:40:43.352015] [20:40:43.352001] [20:40:43.352030] [20:40:43.352028] [20:40:43.352048] Test:  [3/4]  eta: 0:00:03  loss: 0.8609 (0.8582)  acc1: 68.7500 (69.2941)  acc5: 100.0000 (100.0000)  time: 3.9000  data: 3.7298  max mem: 1320\n",
      "[20:40:44.024583] [20:40:44.024567] [20:40:44.025589] [20:40:44.024544] [20:40:44.025638] [20:40:44.025634] [20:40:44.025680] [20:40:44.024347] [20:40:44.025710] [20:40:44.025708] [20:40:44.025753] [20:40:44.025697] [20:40:44.025801] [20:40:44.025799] [20:40:44.025862] Test: Total time: 0:00:16 (4.0728 s / it)\n",
      "[20:40:44.076148] [20:40:44.076127] [20:40:44.076324] [20:40:44.076102] [20:40:44.076399] [20:40:44.076389] [20:40:44.076432] [20:40:44.075922] [20:40:44.076568] [20:40:44.076558] [20:40:44.076597] [20:40:44.076533] [20:40:44.076650] [20:40:44.076647] [20:40:44.076659] > \u001b[0;32m/tmp/ipykernel_2543633/288485815.py\u001b[0m(33)\u001b[0;36mevaluate_test\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     31 \u001b[0;31m        \u001b[0mmetric_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 33 \u001b[0;31m    \u001b[0mall_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.squeeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     34 \u001b[0;31m    \u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.squeeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m    \u001b[0;31m# gather the stats from all processes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  all_predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:16.810885] [20:42:16.810872] [20:42:16.811889] [20:42:16.810865] [20:42:16.811912] [20:42:16.811905] [20:42:16.811921] [20:42:16.810782] [20:42:16.811946] [20:42:16.811943] [20:42:16.811958] [20:42:16.811940] [20:42:16.811973] [20:42:16.811970] [20:42:16.811983] [array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
      "       0, 3, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 2, 2,\n",
      "       2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 1, 1, 1, 0, 2, 0, 0,\n",
      "       0, 4, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 2, 1, 1, 0, 1, 0, 1, 1,\n",
      "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4,\n",
      "       3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2,\n",
      "       0, 0, 0, 1, 0, 2, 1, 0, 0, 4, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 2, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1,\n",
      "       1, 4, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1,\n",
      "       1, 0, 2, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 0, 1, 1, 1, 3, 1,\n",
      "       1, 1, 2, 2, 2, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 4, 4, 2, 0, 2, 1,\n",
      "       2, 0, 2, 0, 2, 2, 1, 4, 0, 1, 0, 1, 2, 0, 2, 1, 2, 2, 1, 1, 2, 0,\n",
      "       2, 2, 2, 1, 1, 0, 2, 1, 1, 4, 0, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 2,\n",
      "       2, 1, 1, 3, 2, 0, 1, 0, 2, 1, 2, 0, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0,\n",
      "       0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 3, 1,\n",
      "       1, 2, 2, 0, 1, 1, 2, 3, 3, 1, 3, 3, 2, 3]), array([2, 3, 3, 0, 2, 4, 2, 2, 1, 2, 2, 3, 1, 2, 2, 3, 1, 1, 1, 3, 2, 4,\n",
      "       0, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 1, 2, 1, 2, 0,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 4, 4, 2, 2, 2, 1, 0,\n",
      "       0, 1, 3, 4, 3, 3, 3, 1, 2, 1, 1, 2, 3, 4, 1, 2, 1, 1, 3, 3, 0, 3,\n",
      "       2, 3, 3, 3, 3, 3, 2, 2, 2, 1, 3, 0, 1, 3, 2, 3, 1, 3, 3, 1, 3, 3,\n",
      "       2, 2, 1, 3, 3, 3, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1,\n",
      "       4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 1,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 0, 2, 1, 2, 4, 4, 0, 4, 4, 4, 4,\n",
      "       4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 4, 4,\n",
      "       4, 4, 0, 4, 1, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 1, 0, 4]), array([4, 4, 1, 0, 4, 0, 4, 4, 0, 1, 0, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 1,\n",
      "       4, 4, 2, 4, 4, 4, 4, 4, 4, 1, 4, 4, 1, 4, 2, 4, 4, 4, 4, 2, 2, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 2, 4, 4, 4, 4,\n",
      "       4, 1, 4, 4, 4, 4, 4, 1, 4, 4, 4, 0, 4, 4, 4, 4])]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  len(all_predictions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:22.339160] [20:42:22.339148] [20:42:22.339765] [20:42:22.339116] [20:42:22.339842] [20:42:22.339832] [20:42:22.340323] [20:42:22.338963] [20:42:22.340927] [20:42:22.340924] [20:42:22.341197] [20:42:22.340743] [20:42:22.341490] [20:42:22.341483] [20:42:22.341517] 4\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.array(all_predictions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:41.482852] [20:42:41.482846] [20:42:41.483174] [20:42:41.482838] [20:42:41.483221] [20:42:41.483215] [20:42:41.483234] [20:42:41.482760] [20:42:41.483265] [20:42:41.483257] [20:42:41.483284] [20:42:41.483254] [20:42:41.483296] [20:42:41.483293] [20:42:41.483307] *** ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_test(data_loader, model, device):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    metric_logger = misc.MetricLogger(delimiter=\"  \")\n",
    "    header = 'Test:'\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in metric_logger.log_every(data_loader, 10, header):\n",
    "        images = batch[0]\n",
    "        target = batch[-1]\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(images)            \n",
    "            loss = criterion(output, target)#\n",
    "            pred = output.argmax(dim=1) \n",
    "        all_predictions.append(pred.cpu().numpy())# ADDED\n",
    "        all_labels.append(target.cpu().numpy())# ADDED\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        \n",
    "        batch_size = images.shape[0]\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
    "        metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
    "    # import pdb;pdb.set_trace()\n",
    "    all_predictions = np.array(all_predictions)#.squeeze(0)\n",
    "    all_labels = np.array(all_labels)#.squeeze(0)\n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    print('* Acc@1 {top1.global_avg:.3f} Acc@5 {top5.global_avg:.3f} loss {losses.global_avg:.3f}'\n",
    "          .format(top1=metric_logger.acc1, top5=metric_logger.acc5, losses=metric_logger.loss))\n",
    "\n",
    "    # return \n",
    "\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}, np.concatenate(all_predictions, axis=0), np.concatenate(all_labels, axis=0)\n",
    "    \n",
    "\n",
    "metrics, all_predictions, all_labels = evaluate_test(data_loader_val, model, device)\n",
    "# print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cff03-b66d-4578-95cd-df5e113bd8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37251664-d171-4983-827a-b8eccbffcb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb3829-f24f-4748-a7a7-0b7c24e26795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0792b94-181c-4582-8a21-6708545a63d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_classes = np.unique(np.concatenate((all_labels, all_predictions)))\n",
    "unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f592c-a922-439c-9656-f211f32fc0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(all_labels, all_predictions, labels=unique_classes)\n",
    "conf_matrix = pd.DataFrame(confusion_mat, index=unique_classes, columns=unique_classes)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d70d9-0d75-478a-a90a-0815db8fdb89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_classes = np.unique(np.concatenate((all_labels, all_predictions)))\n",
    "confusion_mat = confusion_matrix(all_labels, all_predictions, labels=unique_classes)\n",
    "conf_matrix = pd.DataFrame(confusion_mat, index=unique_classes, columns=unique_classes)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(5, 4))\n",
    "ax = sns.heatmap(conf_matrix, annot=True,  fmt='.1f', cmap=sns.cubehelix_palette(as_cmap=True), linewidths=0.1, cbar=True)\n",
    "\n",
    "# Set labels and ticks\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "\n",
    "# Set x and y ticks using the unique classes\n",
    "ax.set_xticks(range(len(unique_classes)))\n",
    "ax.set_yticks(range(len(unique_classes)))\n",
    "\n",
    "# Set x and y ticks at the center of the cells\n",
    "ax.set_xticks([i + 0.5 for i in range(len(unique_classes))])\n",
    "ax.set_yticks([i + 0.5 for i in range(len(unique_classes))])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ac4b1-69e4-4e2b-bb75-65197ad1875c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_multiclass_roc_curve(all_labels, all_predictions, EXPERIMENT_NAME=\".\"):\n",
    "    # Step 1: Label Binarization\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    y_onehot = label_binarizer.fit_transform(all_labels)\n",
    "    all_predictions_hot = label_binarizer.transform(all_predictions)\n",
    "\n",
    "    # Step 2: Calculate ROC curves\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    unique_classes = range(y_onehot.shape[1])\n",
    "    for i in unique_classes:\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_onehot[:, i], all_predictions_hot[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Step 3: Plot ROC curves\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    # Micro-average ROC curve\n",
    "    fpr_micro, tpr_micro, _ = roc_curve(y_onehot.ravel(), all_predictions_hot.ravel())\n",
    "    roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "    plt.plot(\n",
    "        fpr_micro,\n",
    "        tpr_micro,\n",
    "        label=f\"micro-average ROC curve (AUC = {roc_auc_micro:.2f})\",\n",
    "        color=\"deeppink\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    # Macro-average ROC curve\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in unique_classes]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in unique_classes:\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= len(unique_classes)\n",
    "    fpr_macro = all_fpr\n",
    "    tpr_macro = mean_tpr\n",
    "    roc_auc_macro = auc(fpr_macro, tpr_macro)\n",
    "    plt.plot(\n",
    "        fpr_macro,\n",
    "        tpr_macro,\n",
    "        label=f\"macro-average ROC curve (AUC = {roc_auc_macro:.2f})\",\n",
    "        color=\"navy\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    # Individual class ROC curves with unique colors\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_classes)))\n",
    "    for class_id, color in zip(unique_classes, colors):\n",
    "        plt.plot(\n",
    "            fpr[class_id],\n",
    "            tpr[class_id],\n",
    "            color=color,\n",
    "            label=f\"ROC curve for Class {class_id} (AUC = {roc_auc[class_id]:.2f})\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--', linewidth=2)  # Add diagonal line for reference\n",
    "    plt.axis(\"equal\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Extension of Receiver Operating Characteristic\\n to One-vs-Rest multiclass\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{EXPERIMENT_NAME}/roc_curve.png')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "    \n",
    "plot_multiclass_roc_curve(all_labels, all_predictions, EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806d2d76-84c6-4020-8bfb-56f545976b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def visualize_predictions(model, val_loader, device, type_label=None, dataset_type=1, unique_classes=np.array([0, 1, 2, 3, 4, 5, 6])):\n",
    "\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     metric_logger = misc.MetricLogger(delimiter=\"  \")\n",
    "#     header = 'Test:'\n",
    "\n",
    "#     # switch to evaluation mode\n",
    "#     model.eval()\n",
    "#     all_predictions = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     for batch in metric_logger.log_every(val_loader, 10, header):\n",
    "#         images = batch[0]\n",
    "#         target = batch[-1]\n",
    "#         images = images.to(device, non_blocking=True)\n",
    "#         target = target.to(device, non_blocking=True)\n",
    "\n",
    "#         # compute output\n",
    "#         with torch.cuda.amp.autocast():\n",
    "#             output = model(images)            \n",
    "#             loss = criterion(output, target)#\n",
    "#             pred = output.argmax(dim=1) \n",
    "#         all_predictions.append(pred.cpu().numpy())# ADDED\n",
    "#         all_labels.append(target.cpu().numpy())# ADDED\n",
    "#         acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        \n",
    "#         batch_size = images.shape[0]\n",
    "#         metric_logger.update(loss=loss.item())\n",
    "#         metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
    "#         metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
    "    \n",
    "#     all_predictions = np.array(all_predictions)#.squeeze(0)\n",
    "#     all_labels = np.array(all_labels)#.squeeze(0)\n",
    "\n",
    "#     if type_label is None:\n",
    "#         type_label = unique_classes\n",
    "\n",
    "#     # Create a 4x4 grid for visualization\n",
    "#     num_rows = 4\n",
    "#     num_cols = 4\n",
    "\n",
    "#     plt.figure(figsize=(12, 12))\n",
    "\n",
    "#     for i in range(num_rows * num_cols):\n",
    "#         plt.subplot(num_rows, num_cols, i + 1)\n",
    "#         idx = np.random.randint(len(all_labels))\n",
    "#         import pdb;pdb.set_trace()\n",
    "#         plt.imshow(images[idx].cpu().numpy().squeeze(), cmap='gray')\n",
    "\n",
    "#         # Use the class names instead of numeric labels for Fashion MNIST\n",
    "#         if dataset_type == 1:\n",
    "#             class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "#             predicted_class = class_names[all_predictions[idx]]\n",
    "#             actual_class = class_names[all_labels[idx]]\n",
    "#         else:\n",
    "#             predicted_class = all_predictions[idx]\n",
    "#             actual_class = all_labels[idx]\n",
    "\n",
    "#         plt.title(f'Pred: {predicted_class}\\nActual: {actual_class}')\n",
    "#         plt.axis('off')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# visualize_predictions(model, data_loader_val, device, dataset_type=2, unique_classes=unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b1388-0d8d-49a4-9547-c4b0de31fcc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232cf15-0edb-4546-993a-a9839441c967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report = classification_report(all_labels, all_predictions, target_names=unique_classes,output_dict=True)# Mostrar el informe de \n",
    "\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_csv(os.path.join(EXPERIMENT_NAME, \"confusion_matrix.csv\"))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a60e2d-eebc-4547-91be-3d7dac0226da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c907e5c-a3e0-4eae-9994-082b269732d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and specificity (micro-averaged)\n",
    "precision = precision_score(all_labels, all_predictions, average='micro')\n",
    "recall = recall_score(all_labels, all_predictions, average='micro')\n",
    "\n",
    "# Calculate true negatives, false positives, and specificity (micro-averaged)\n",
    "tn = np.sum((all_labels != 1) & (all_predictions != 1))\n",
    "fp = np.sum((all_labels != 1) & (all_predictions == 1))\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Calculate F1 score (weighted average)\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "evaluation_metrics = {\n",
    "    \"Acc1\": metrics['acc1'],  # Add acc1 metric\n",
    "    \"Acc5\": metrics['acc5'],  # Add acc5 metric\n",
    "    \"loss\": metrics['loss'],  # Add acc5 metric\n",
    "    \"F1 Score\": [f1],\n",
    "    \"Precision\": [precision],\n",
    "    \"Recall\": [recall],\n",
    "    \"Specificity\": [specificity]\n",
    "}\n",
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cffce5-3186-440c-bc5c-aba6fae47d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(evaluation_metrics)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(f'{EXPERIMENT_NAME}/evaluation_metrics_for_table.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15f4cc-9861-4be1-97c3-976f8e8014b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252dbe67-f9c2-4ac0-92cb-be76a4d58d3d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retfound",
   "language": "python",
   "name": "retfound"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
